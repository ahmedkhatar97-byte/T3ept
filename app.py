import streamlit as st
import google.generativeai as genai
from PIL import Image
from streamlit_mic_recorder import mic_recorder
import time

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ---
# âš ï¸ Ø­Ø· Ø§Ù„Ù€ API Key Ø¨ØªØ§Ø¹Ùƒ Ù‡Ù†Ø§ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù„Ø§Ù…ØªÙŠÙ†
MY_API_KEY = "AIzaSyCOdFVcx0W2pdlfh5uDTq-v5DN2zD2ZfWU" 

genai.configure(api_key=MY_API_KEY)

# Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø­Ø±ÙŠ Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ 404 ØªØ®ØªÙÙŠ
model = genai.GenerativeModel('gemini-1.5-flash-latest')

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø´ÙŠÙƒ ---
st.set_page_config(page_title="X ASSISTANT v2", page_icon="âš¡", layout="wide")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap');
    .stApp { background-color: #050505; color: #ffffff; }
    .main-title {
        font-family: 'Orbitron', sans-serif;
        font-size: 50px;
        background: linear-gradient(to right, #00f2fe, #4facfe);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: bold;
        text-align: center;
    }
    .stChatMessage { border-radius: 15px; border: 1px solid #1e272e; }
    </style>
    """, unsafe_allow_html=True)

# --- Ø§Ù„Ø£Ù†ÙŠÙ…ÙŠØ´Ù† Ø¨ØªØ§Ø¹ Ø§Ù„Ø¯Ø®ÙˆÙ„ ---
if 'entry' not in st.session_state:
    placeholder = st.empty()
    with placeholder.container():
        st.markdown('<div style="text-align:center; padding:100px;"><h1 class="main-title">X ASSISTANT v2</h1><p style="color:#4facfe;">System Loading...</p></div>', unsafe_allow_html=True)
        time.sleep(2)
    st.session_state.entry = True
    placeholder.empty()

# --- Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
if "user_name" not in st.session_state:
    st.session_state.user_name = "Harreef"

# --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ØµÙˆØ± ÙˆØµÙˆØª) ---
with st.sidebar:
    st.markdown(f"### Ø£Ù‡Ù„Ø§Ù‹ ÙŠØ§ **{st.session_state.user_name}** ğŸ˜")
    st.divider()
    
    st.write("ğŸ“¸ **Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:**")
    up_img = st.file_uploader("", type=["jpg", "png", "jpeg"])
    
    st.divider()
    st.write("ğŸ¤ **Ø³Ø¬Ù„ Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©:**")
    # Ø¥Ø¶Ø§ÙØ© Ø²Ø± Ø§Ù„ØµÙˆØª Ø¨Ø¬Ø§Ù†Ø¨ Ø®Ø§Ù†Ø© Ø§Ù„Ø´Ø§Øª (Ù‡Ù†Ø§ ÙÙŠ Ø§Ù„Ø¬Ù†Ø¨ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±)
    audio_record = mic_recorder(start_prompt="Ø¥Ø¨Ø¯Ø£ Ø§Ù„ÙƒÙ„Ø§Ù… ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='mic')
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.chat = model.start_chat(history=[])
        st.rerun()

# --- Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ---
for msg in st.session_state.chat.history:
    role = "user" if msg.role == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(msg.parts[0].text)

# --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ---
prompt = st.chat_input("ØªØ¤Ù…Ø±Ù†ÙŠ Ø¨Ø¥ÙŠÙ‡ ÙŠØ§ HarreefØŸ")

# Ø¯Ù…Ø¬ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ùˆ ÙˆØ¬Ø¯Øª
if audio_record and not prompt:
    prompt = "Ù„Ù‚Ø¯ Ø£Ø±Ø³Ù„Øª Ù„Ùƒ ØªØ³Ø¬ÙŠÙ„Ø§Ù‹ ØµÙˆØªÙŠØ§Ù‹ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø®ØµÙˆØµÙ‡ØŸ"

if prompt:
    # Ø­ÙØ¸ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ùˆ Ù‚Ø§Ù„Ù‡
    if "Ø§Ø³Ù…ÙŠ" in prompt:
        st.session_state.user_name = prompt.split("Ø§Ø³Ù…ÙŠ")[-1].strip()

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙÙƒØ±..."):
            try:
                if up_img:
                    img = Image.open(up_img)
                    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø©
                    response = st.session_state.chat.send_message([prompt, img])
                else:
                    response = st.session_state.chat.send_message(prompt)
                
                st.markdown(response.text)
            except Exception as e:
                # Ø­Ù„ Ø°ÙƒÙŠ Ù„Ùˆ Ø­ØµÙ„ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØªØ§Ù†ÙŠ
                st.error(f"Ø¹Ø°Ø±Ø§Ù‹ ÙŠØ§ Ø­Ø±ÙŠÙØŒ Ø­ØµÙ„ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
  
